{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dc7d49e",
   "metadata": {},
   "source": [
    "# 사이킷런 손글씨 데이터를 활용하여 주성분 줄이기 차이 (결과값 비교)\n",
    "\n",
    "데이터 스케일 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ea5fda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc4c893",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78d5675a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1797\n",
      "1797\n",
      "[[ 0.  0.  1. ...  8.  0.  0.]\n",
      " [ 0.  0.  6. ... 16. 16. 14.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  2. 15. ...  0.  0.  0.]\n",
      " [ 0.  0.  3. ... 10.  0.  0.]\n",
      " [ 0.  4. 13. ...  0.  0.  0.]]\n",
      "1347 450\n",
      "1347 450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n이걸 더 연습하고 싶을 때 실습 방법\\n1. 폴더 생성 (이미지 100개)\\n2. 폴더 읽고 -> train val test 나눠서 폴더 생성해서 거기에 이미지 저장\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "digits = load_digits()\n",
    "\n",
    "# 진짜 차이가 있는지 체크 하기 위해서 -> 정규화 하지 않은 데이터로 분류 모델 훈련\n",
    "print(len(digits.data))\n",
    "print(len(digits.target))       # 라벨 개수\n",
    "x_train, x_test, y_train, y_test = train_test_split(digits.data, digits.target, random_state = 777)\n",
    "# test_size : 몇 %만 test로 둘 건지 지정\n",
    "\n",
    "# 진짜 나누어졌는지 확인\n",
    "print(x_train)\n",
    "print(len(x_train), len(x_test))\n",
    "print(len(y_train), len(y_test))\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "이걸 더 연습하고 싶을 때 실습 방법\n",
    "1. 폴더 생성 (이미지 100개)\n",
    "2. 폴더 읽고 -> train val test 나눠서 폴더 생성해서 거기에 이미지 저장\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e386064",
   "metadata": {},
   "source": [
    "## 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a52dbdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without normalization :  0.9511111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smjin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "no_standardScaler_acc_score = accuracy_score(y_test, y_pred)   # 정답지 예측치\n",
    "print(\"Accuracy without normalization : \", no_standardScaler_acc_score)\n",
    "\n",
    "# standard 적용 전"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64564ab9",
   "metadata": {},
   "source": [
    "## StandardScaler 적용 후 -> ACC\n",
    "- StandardScaler : 평균 0, 분산 1로 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29861fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with normalization :  0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 데이터 정규화 후 분류 모델 확인\n",
    "scaler = StandardScaler()\n",
    "x_train_norm = scaler.fit_transform(x_train)\n",
    "x_test_norm = scaler.transform(x_test)\n",
    "model_norm = LogisticRegression()\n",
    "model_norm.fit(x_train_norm, y_train)\n",
    "y_pred_norm = model_norm.predict(x_test_norm)\n",
    "\n",
    "standardScale_acc_score = accuracy_score(y_test, y_pred_norm)\n",
    "print(\"Accuracy with normalization : \", standardScale_acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2a1a699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9511111111111111 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "# 두 개의 차이 보기\n",
    "print(no_standardScaler_acc_score, standardScale_acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a728807",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
